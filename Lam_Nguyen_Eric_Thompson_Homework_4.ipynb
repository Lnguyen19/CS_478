{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lnguyen19/CS_478/blob/main/Lam_Nguyen_Eric_Thompson_Homework_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDZ2LohhcMpO",
        "outputId": "c7bf81e3-1b6c-4352-e91d-0aee20a2f9e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  class                                            message\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "PRINTING CLASS DATA\n",
            "     class\n",
            "0      ham\n",
            "1      ham\n",
            "2     spam\n",
            "3      ham\n",
            "4      ham\n",
            "...    ...\n",
            "5400   ham\n",
            "5401   ham\n",
            "5402   ham\n",
            "5403   ham\n",
            "5404   ham\n",
            "\n",
            "[5405 rows x 1 columns]\n",
            "PRINTING MESSAGE DATA\n",
            "0       Go until jurong point, crazy.. Available only ...\n",
            "1                           Ok lar... Joking wif u oni...\n",
            "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3       U dun say so early hor... U c already then say...\n",
            "4       Nah I don't think he goes to usf, he lives aro...\n",
            "                              ...                        \n",
            "5400    HARD BUT TRUE: How much you show &amp;  expres...\n",
            "5401    Babes I think I got ur brolly I left it in Eng...\n",
            "5402    Hi babe its me thanks for coming even though i...\n",
            "5403             So gd got free ice cream... I oso wan...\n",
            "5404    Pls give her prometazine syrup. 5mls then  &lt...\n",
            "Name: message, Length: 5405, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# 1\n",
        "# Load the dependencies and your data set.\n",
        "import keras\n",
        "from keras.datasets import imdb\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.layers import Embedding, SpatialDropout1D, Conv1D, GlobalMaxPool1D, Conv1D, MaxPooling1D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.layers import SimpleRNN\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Reading in data from url\n",
        "dataset_url = 'https://raw.githubusercontent.com/WithAPorpoise/public_datasets/main/spam_ham_dataset.csv'\n",
        "data = pd.read_csv(dataset_url, usecols=[\"class\", \"message\"]) # Ignore NaN columns\n",
        "print(data.head())\n",
        "\n",
        "# Split message and class columns into variables\n",
        "message_data = data.message               # X\n",
        "class_data = data.drop('message', axis=1) # Y\n",
        "print(\"PRINTING CLASS DATA\")\n",
        "print(class_data)\n",
        "print(\"PRINTING MESSAGE DATA\")\n",
        "print(message_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "# Separate your data set between train and test in a 70/30 split. \n",
        "# Additionally, I would like you to print a graph of the number of \n",
        "# label_value_counts() of the data set to show the distribution of labels.\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(message_data, class_data, test_size=0.3)\n",
        "class_data['class'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "5dl9Ijo8cqxa",
        "outputId": "ad3b46ea-6e69-46aa-af80-dcba026c11a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbee2bbbf50>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4\n",
        "#    Set your hyperparameters:\n",
        "\n",
        "#    epochs,\n",
        "#    batch size,\n",
        "#    dimension,\n",
        "#    unique words,\n",
        "#    stop words,\n",
        "#    maximum message length,\n",
        "#    padding type,\n",
        "#    truncation type,\n",
        "#    #dense layer,\n",
        "#    dropout,\n",
        "#    n_filters,\n",
        "#    optimizers,\n",
        "#    or anything else needed.\n",
        "\n",
        "output_dir = 'model_output/dense'\n",
        "epochs = 4\n",
        "batch_size = 128\n",
        "\n",
        "n_dim = 100\n",
        "n_unique_words = 5000\n",
        "n_words_to_skip = 50\n",
        "pad_type = trunc_type = 'pre'\n",
        "n_dense = 100\n",
        "dropout = 0.5\n",
        "#CNN\n",
        "cnn_max_review =400 \n",
        "cnn_dense = 256\n",
        "cnn_dropout = 0.2\n",
        "n_conv = 256\n",
        "k_conv = 3\n",
        "\n",
        "\n",
        "#RNN\n",
        "n_rnn = 256\n",
        "drop_rnn = 0.2\n",
        "drop_embed = 0.2\n",
        "#LSTM\n",
        "out_put_ = 'model_output/conv'\n",
        "lstm_max_review = 400\n",
        "lstm_drop_embed = 0.2\n",
        "lstm_n_conv = 256 \n",
        "lstm_k_conv = 0.2\n",
        "lstm_dropout = 0.2"
      ],
      "metadata": {
        "id": "3r0KvUeRc7Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "# Apply all ( or subset of) the preprocessing steps that we learned in the class:\n",
        "# Tokenization\n",
        "# Convertion to lowercase\n",
        "# Removing stop words\n",
        "# Removing puntuation\n",
        "# Stemming\n",
        "# n-grams\n",
        "# Converting tokens into an integer index\n",
        "#x_train = pad_sequences(x_train,maxlen=max_review_length,padding = pad_type,truncating=trunc_type,value=0)\n",
        "#x_test = pad_sequences(x_test,maxlen=max_review_length,padding = pad_type,truncating=trunc_type,value=0)\n",
        "\n",
        "# Tokenizing\n",
        "max_review_length = 100\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(x_train)\n",
        "token.fit_on_texts(x_test)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "x_train = pad_sequences(x_train, maxlen=max_review_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_review_length)\n",
        "print(x_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "uLUYOqZOczUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e68805d-cff5-4c3d-afcb-c873176a2ef0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ...   74  225  129]\n",
            " [   0    0    0 ...  132   23 1215]\n",
            " [   0    0    0 ...   58  104 1430]\n",
            " ...\n",
            " [   0    0    0 ...  126   22    3]\n",
            " [   0    0    0 ...   58 1093   45]\n",
            " [   0    0    0 ...  651  140  264]]\n",
            "(3783, 100)\n",
            "(1622, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5\n",
        "#     Create, fit and evaluate the following models:\n",
        "\n",
        "# Follow the instructions laid out from class lecture. Create one of each of the following models:\n",
        "\n",
        "#    Dense\n",
        "#    Convolutional\n",
        "#    Simple RNN\n",
        "#    LSTM\n",
        "\n",
        "# Dense\n",
        "model1 = Sequential() # Each layer flows to the next\n",
        "#1st hidden layer\n",
        "model1.add(Embedding(n_unique_words, n_dim, input_length=max_review_length))\n",
        "model1.add(Flatten())\n",
        "#2nd hidden layer\n",
        "model1.add(Dense(n_dense, activation='relu'))\n",
        "model1.add(Dropout(dropout))\n",
        "#3rd hidden layer if needed more\n",
        "model1.add(Dense(n_dense, activation='relu'))\n",
        "model1.add(Dropout(dropout))\n",
        "#Output layer: Single sigmoid neuron to predict binary classification\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# CNN\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(n_unique_words, n_dim, input_length=cnn_max_review))\n",
        "model2.add(SpatialDropout1D(drop_embed))\n",
        "model2.add(Conv1D(n_conv,k_conv,activation = 'relu'))\n",
        "model2.add(GlobalMaxPool1D())\n",
        "model2.add(Dense(cnn_dense,activation='relu'))\n",
        "model2.add(Dropout(cnn_dropout))\n",
        "model2.add(Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "# RNN\n",
        "model3 = Sequential()\n",
        "#1st hidden layer\n",
        "model3.add(Embedding(n_unique_words, n_dim, input_length=max_review_length))\n",
        "model3.add(SpatialDropout1D(drop_embed))\n",
        "#2nd hidden layer\n",
        "model3.add(SimpleRNN(n_rnn, dropout=drop_rnn))\n",
        "#output layer\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# LSTM\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(n_unique_words, n_dim, input_length= lstm_max_review)) \n",
        "model4.add(SpatialDropout1D(lstm_drop_embed))\n",
        "#model4.add(Conv1D(lstm_n_conv, lstm_k_conv, activation='relu'))\n",
        "#model4.add(GlobalMaxPool1D())\n",
        "model4.add(Dense(n_dense, activation='relu'))\n",
        "model4.add(Dropout(lstm_dropout))\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "# Compiling\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#\n",
        "# Graph execution error here, can't figure out why. data is tokenized\n",
        "#\n",
        "history1 =  model1.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "history2 =  model2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "history3 =  model3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "history4 =  model4.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "SRtlquVzdEBM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00b46e4c-a0e0-4f5d-d31c-a979ee97edef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-b109ad7ec9ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Graph execution error here, can't figure out why. data is tokenized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mhistory1\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0mhistory2\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mhistory3\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/Cast' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 787, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n      yield self.process_one()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 225, in wrapper\n      runner = Runner(result, future, yielded)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 714, in __init__\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-85-b109ad7ec9ed>\", line 63, in <module>\n      history1 =  model1.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 949, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1777, in categorical_crossentropy\n      y_true = tf.cast(y_true, y_pred.dtype)\nNode: 'categorical_crossentropy/Cast'\nCast string to float is not supported\n\t [[{{node categorical_crossentropy/Cast}}]] [Op:__inference_train_function_13182]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluations can be done on the basis of ROC-AUC. You have to draw the ROC-AUC curve for each model.\n",
        "# Dense\n",
        "y_hat1 = model1.predict(x_test)\n",
        "fpr , tpr , thresholds = roc_curve (y_test , y_hat1)\n",
        "plt.plot(fpr,tpr) \n",
        "plt.axis([0,1,0,1]) \n",
        "plt.title('False Positive Rate vs True Positive Rate ROC-AUC')\n",
        "plt.xlabel('False Positive Rate') \n",
        "plt.ylabel('True Positive Rate') \n",
        "plt.show()\n",
        "\n",
        "# CNN\n",
        "y_hat2 = model2.predict(x_test)\n",
        "fpr , tpr , thresholds = roc_curve (y_test , y_hat2)\n",
        "plt.plot(fpr,tpr) \n",
        "plt.axis([0,1,0,1]) \n",
        "plt.title('False Positive Rate vs True Positive Rate ROC-AUC')\n",
        "plt.xlabel('False Positive Rate') \n",
        "plt.ylabel('True Positive Rate') \n",
        "plt.show()\n",
        "\n",
        "# RNN\n",
        "y_hat3 = model3.predict(x_test)\n",
        "fpr , tpr , thresholds = roc_curve (y_test , y_hat3)\n",
        "plt.plot(fpr,tpr) \n",
        "plt.axis([0,1,0,1]) \n",
        "plt.title('False Positive Rate vs True Positive Rate ROC-AUC')\n",
        "plt.xlabel('False Positive Rate') \n",
        "plt.ylabel('True Positive Rate') \n",
        "plt.show()\n",
        "\n",
        "# LSTM\n",
        "y_hat4 = model4.predict(x_test)\n",
        "fpr , tpr , thresholds = roc_curve (y_test , y_hat4)\n",
        "plt.plot(fpr,tpr) \n",
        "plt.axis([0,1,0,1]) \n",
        "plt.title('False Positive Rate vs True Positive Rate ROC-AUC')\n",
        "plt.xlabel('False Positive Rate') \n",
        "plt.ylabel('True Positive Rate') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OGYVHEK6IHEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6\n",
        "#    Tune your model\n",
        "\n",
        "# Select the model which performed the best in the previous step and then tune the hyperparameters\n"
      ],
      "metadata": {
        "id": "c2MsqF3FdQLS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}